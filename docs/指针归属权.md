关于Tensor操作函数，除了哪些在函数名中标出了Implace的函数，其他函数都会创建一个新的Tensor，而且不会释放老的Tensor。


对于Layer，一旦用某个Tensor调用了Layer的forward，那么这个input Tensor的所有权就立即归此Layer所有。而Layer返回的Output Tensor所有权属于调用者（Layer应当自己复制一份Output Tensor保存在内部）

一旦第二次调用Layer的forward，这个Layer将立即释放上一轮保存的input Tensor和output Tensor。

调用Layer的backward，这个input Tensor的所有权不归Layer所有，返回的Output Tensor所有权属于调用者。每轮backward调用时，会修改内部存储的grads


Loss不保有任何Tensor的所有权

Optim保有每个Layer的grad的读权限，以及params的读写写权限，它不会释放任何Tensor

Graph(Module)保有Optim、Loss的所有权，此外它还拥有所有Layer的所有权，它可以释放Layer



